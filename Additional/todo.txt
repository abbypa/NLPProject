- normalize each classifier (maybe using "normal word")
- connect classifier to tokenizer
- add sleep between searches (currently 1 second beforeprocessing a new line maybe it should be done more often?)
- more classifers- save words before hits
- tokenizer optimizations ('-)
- installation script
- after more runs (to find bugs)- surround all api calls with try-except and return an empty result