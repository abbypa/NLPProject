- normalize each classifier (maybe using "normal word")
- connect classifier to tokenizer
- add sleep between searches (currently 1 second beforeprocessing a new line maybe it should be done more often?)
- more classifers- save words before hits
- tokenizer optimizations ('-)
- installation script
- consider- selecting NE if some categories are "close enough" (not just all equal)


duckduckgo error:
C:\Users\Nini\Desktop\limudim\nlproj\git\Main.py "C:\Users\Nini\Desktop\limudim\nlproj\git\Additional\tiny_corpus.txt"
Traceback (most recent call last):
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\Main.py", line 19, in <module>
    __main__(sys.argv[1:])
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\Main.py", line 11, in __main__
    process_corpus("eng1",1,argv[0])
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\ProcessCorpus.py", line 22, in process_corpus
    result = test_term(result,line,i,term,"backword")
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\ProcessCorpus.py", line 41, in test_term
    grades = classify(" ".join(term)).Matches
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\Classification.py", line 96, in  classify
    result = weighted_classifier[0].classify(term)
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\Classification.py", line 14, in classify
    search_result = self.duckduckgo_search.general_search(term)
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\DuckduckgoSearch.py", line 26,in general_search
    all_results += self.try_add_results(r, "related")
  File "C:\Users\Nini\Desktop\limudim\nlproj\git\DuckduckgoSearch.py", line 47,in try_add_results
    result_str += self.try_add_text_and_url(result)
TypeError: cannot concatenate 'str' and 'NoneType' objects
